{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tpr_weight_funtion(y_true,y_predict):\n",
    "    d = pd.DataFrame()\n",
    "    d['prob'] = list(y_predict)\n",
    "    d['y'] = list(y_true)\n",
    "    d = d.sort_values(['prob'], ascending=[0])\n",
    "    y = d.y\n",
    "    PosAll = pd.Series(y).value_counts()[1]\n",
    "    NegAll = pd.Series(y).value_counts()[0]\n",
    "    pCumsum = d['y'].cumsum()\n",
    "    nCumsum = np.arange(len(y)) - pCumsum + 1\n",
    "    pCumsumPer = pCumsum / PosAll\n",
    "    nCumsumPer = nCumsum / NegAll\n",
    "    TR1 = pCumsumPer[abs(nCumsumPer-0.001).idxmin()]\n",
    "    TR2 = pCumsumPer[abs(nCumsumPer-0.005).idxmin()]\n",
    "    TR3 = pCumsumPer[abs(nCumsumPer-0.01).idxmin()]\n",
    "    return 'TC_AUC',0.4 * TR1 + 0.3 * TR2 + 0.3 * TR3,True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Program Files\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:2717: DtypeWarning: Columns (8) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "op_train = pd.read_csv('../data/operation_train_new.csv')\n",
    "trans_train = pd.read_csv('../data/transaction_train_new.csv')\n",
    "\n",
    "op_test = pd.read_csv('../data/test_operation_round2.csv')\n",
    "trans_test = pd.read_csv('../data/test_transaction_round2.csv')\n",
    "y = pd.read_csv('../data/tag_train_new.csv')\n",
    "sub = pd.read_csv('../data/example.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trans_train = trans_train.drop(['day','trans_amt','bal'],axis=1)\n",
    "trans_test = trans_test.drop(['day','trans_amt','bal'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "op_train = op_train.drop(['day'],axis=1)\n",
    "op_test = op_test.drop(['day'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_feature(op,trans,label):\n",
    "    for feature in op.columns[:]:\n",
    "        if feature not in ['day']:\n",
    "            if feature != 'UID':\n",
    "                label = label.merge(op.groupby(['UID'])[feature].count().reset_index(),on='UID',how='left')\n",
    "                label =label.merge(op.groupby(['UID'])[feature].nunique().reset_index(),on='UID',how='left')\n",
    "            for deliver in ['ip1','mac1','mac2','geo_code']:\n",
    "                if feature not in deliver:\n",
    "                    if feature != 'UID':\n",
    "                        temp = op[['UID',deliver]].merge(op.groupby([deliver])[feature].count().reset_index(),on=deliver,how='left')[['UID',feature]] \n",
    "                        temp = temp.groupby('UID')[feature].sum().reset_index()\n",
    "                        temp.columns = ['UID',feature+deliver]\n",
    "                        label =label.merge(temp,on='UID',how='left')\n",
    "                        del temp\n",
    "                        temp = op[['UID',deliver]].merge(op.groupby([deliver])[feature].nunique().reset_index(),on=deliver,how='left')[['UID',feature]] \n",
    "                        temp = temp.groupby('UID')[feature].sum().reset_index()\n",
    "                        temp.columns = ['UID',feature+deliver]\n",
    "                        label =label.merge(temp,on='UID',how='left')\n",
    "                        del temp\n",
    "                    else:\n",
    "                        temp = op[['UID',deliver]].merge(op.groupby([deliver])[feature].count().reset_index(),on=deliver,how='left')[['UID_x','UID_y']] \n",
    "                        temp = temp.groupby('UID_x')['UID_y'].sum().reset_index()\n",
    "                        temp.columns = ['UID',feature+deliver]\n",
    "                        label =label.merge(temp,on='UID',how='left')\n",
    "                        del temp\n",
    "                        temp = op[['UID',deliver]].merge(op.groupby([deliver])[feature].nunique().reset_index(),on=deliver,how='left')[['UID_x','UID_y']] \n",
    "                        temp = temp.groupby('UID_x')['UID_y'].sum().reset_index()\n",
    "                        temp.columns = ['UID',feature+deliver]\n",
    "                        label =label.merge(temp,on='UID',how='left')\n",
    "                        del temp\n",
    "        else:\n",
    "            print(feature)\n",
    "            label =label.merge(op.groupby(['UID'])[feature].count().reset_index(),on='UID',how='left')\n",
    "            label =label.merge(op.groupby(['UID'])[feature].nunique().reset_index(),on='UID',how='left')\n",
    "            label =label.merge(op.groupby(['UID'])[feature].max().reset_index(),on='UID',how='left')\n",
    "            label =label.merge(op.groupby(['UID'])[feature].min().reset_index(),on='UID',how='left')\n",
    "            label =label.merge(op.groupby(['UID'])[feature].sum().reset_index(),on='UID',how='left')\n",
    "            label =label.merge(op.groupby(['UID'])[feature].mean().reset_index(),on='UID',how='left')\n",
    "            label =label.merge(op.groupby(['UID'])[feature].std().reset_index(),on='UID',how='left')\n",
    "            for deliver in ['ip1','mac1','mac2']:\n",
    "                if feature not in deliver:\n",
    "                    temp = op[['UID',deliver]].merge(op.groupby([deliver])[feature].count().reset_index(),on=deliver,how='left')[['UID',feature]] \n",
    "                    temp = temp.groupby('UID')[feature].sum().reset_index()\n",
    "                    temp.columns = ['UID',feature+deliver]\n",
    "                    label =label.merge(temp,on='UID',how='left')\n",
    "                    del temp\n",
    "                    temp = op[['UID',deliver]].merge(op.groupby([deliver])[feature].nunique().reset_index(),on=deliver,how='left')[['UID',feature]] \n",
    "                    temp = temp.groupby('UID')[feature].sum().reset_index()\n",
    "                    temp.columns = ['UID',feature+deliver]\n",
    "                    label =label.merge(temp,on='UID',how='left')\n",
    "                    del temp\n",
    "                    temp = op[['UID',deliver]].merge(op.groupby([deliver])[feature].max().reset_index(),on=deliver,how='left')[['UID',feature]] \n",
    "                    temp = temp.groupby('UID')[feature].mean().reset_index()\n",
    "                    temp.columns = ['UID',feature+deliver]\n",
    "                    label =label.merge(temp,on='UID',how='left')\n",
    "                    del temp\n",
    "                    temp = op[['UID',deliver]].merge(op.groupby([deliver])[feature].min().reset_index(),on=deliver,how='left')[['UID',feature]] \n",
    "                    temp = temp.groupby('UID')[feature].mean().reset_index()\n",
    "                    temp.columns = ['UID',feature+deliver]\n",
    "                    label =label.merge(temp,on='UID',how='left')\n",
    "                    del temp\n",
    "                    temp = op[['UID',deliver]].merge(op.groupby([deliver])[feature].sum().reset_index(),on=deliver,how='left')[['UID',feature]] \n",
    "                    temp = temp.groupby('UID')[feature].mean().reset_index()\n",
    "                    temp.columns = ['UID',feature+deliver]\n",
    "                    label =label.merge(temp,on='UID',how='left')\n",
    "                    del temp\n",
    "                    temp = op[['UID',deliver]].merge(op.groupby([deliver])[feature].mean().reset_index(),on=deliver,how='left')[['UID',feature]] \n",
    "                    temp = temp.groupby('UID')[feature].mean().reset_index()\n",
    "                    temp.columns = ['UID',feature+deliver]\n",
    "                    label =label.merge(temp,on='UID',how='left')\n",
    "                    del temp\n",
    "                    temp = op[['UID',deliver]].merge(op.groupby([deliver])[feature].std().reset_index(),on=deliver,how='left')[['UID',feature]] \n",
    "                    temp = temp.groupby('UID')[feature].mean().reset_index()\n",
    "                    temp.columns = ['UID',feature+deliver]\n",
    "                    label =label.merge(temp,on='UID',how='left')\n",
    "                    del temp\n",
    "                    \n",
    "                    \n",
    "                    \n",
    "    for feature in trans.columns[1:]:\n",
    "        if feature not in ['trans_amt','bal','day']:\n",
    "            if feature != 'UID':\n",
    "                label =label.merge(trans.groupby(['UID'])[feature].count().reset_index(),on='UID',how='left')\n",
    "                label =label.merge(trans.groupby(['UID'])[feature].nunique().reset_index(),on='UID',how='left')\n",
    "            for deliver in ['merchant','ip1','mac1','geo_code']:\n",
    "                if feature not in deliver: \n",
    "                    if feature != 'UID':\n",
    "                        temp = trans[['UID',deliver]].merge(trans.groupby([deliver])[feature].count().reset_index(),on=deliver,how='left')[['UID',feature]] \n",
    "                        temp = temp.groupby('UID')[feature].sum().reset_index()\n",
    "                        temp.columns = ['UID',feature+deliver]\n",
    "                        label =label.merge(temp,on='UID',how='left')\n",
    "                        del temp\n",
    "                        temp = trans[['UID',deliver]].merge(trans.groupby([deliver])[feature].nunique().reset_index(),on=deliver,how='left')[['UID',feature]] \n",
    "                        temp = temp.groupby('UID')[feature].sum().reset_index()\n",
    "                        temp.columns = ['UID',feature+deliver]\n",
    "                        label =label.merge(temp,on='UID',how='left')\n",
    "                        del temp\n",
    "                    else:\n",
    "                        temp = trans[['UID',deliver]].merge(trans.groupby([deliver])[feature].count().reset_index(),on=deliver,how='left')[['UID_x','UID_y']] \n",
    "                        temp = temp.groupby('UID_x')['UID_y'].sum().reset_index()\n",
    "                        temp.columns = ['UID',feature+deliver]\n",
    "                        label =label.merge(temp,on='UID',how='left')\n",
    "                        del temp\n",
    "                        temp = trans[['UID',deliver]].merge(trans.groupby([deliver])[feature].nunique().reset_index(),on=deliver,how='left')[['UID_x','UID_y']] \n",
    "                        temp = temp.groupby('UID_x')['UID_y'].sum().reset_index()\n",
    "                        temp.columns = ['UID',feature+deliver]\n",
    "                        label =label.merge(temp,on='UID',how='left')\n",
    "                        del temp\n",
    "\n",
    "        else:\n",
    "            print(feature)\n",
    "            label =label.merge(trans.groupby(['UID'])[feature].count().reset_index(),on='UID',how='left')\n",
    "            label =label.merge(trans.groupby(['UID'])[feature].nunique().reset_index(),on='UID',how='left')\n",
    "            label =label.merge(trans.groupby(['UID'])[feature].max().reset_index(),on='UID',how='left')\n",
    "            label =label.merge(trans.groupby(['UID'])[feature].min().reset_index(),on='UID',how='left')\n",
    "            label =label.merge(trans.groupby(['UID'])[feature].sum().reset_index(),on='UID',how='left')\n",
    "            label =label.merge(trans.groupby(['UID'])[feature].mean().reset_index(),on='UID',how='left')\n",
    "            label =label.merge(trans.groupby(['UID'])[feature].std().reset_index(),on='UID',how='left')\n",
    "            for deliver in ['merchant','ip1','mac1']:\n",
    "                if feature not in deliver:\n",
    "                    temp = trans[['UID',deliver]].merge(trans.groupby([deliver])[feature].count().reset_index(),on=deliver,how='left')[['UID',feature]] \n",
    "                    temp = temp.groupby('UID')[feature].sum().reset_index()\n",
    "                    temp.columns = ['UID',feature+deliver]\n",
    "                    label =label.merge(temp,on='UID',how='left')\n",
    "                    del temp\n",
    "                    temp = trans[['UID',deliver]].merge(trans.groupby([deliver])[feature].nunique().reset_index(),on=deliver,how='left')[['UID',feature]] \n",
    "                    temp = temp.groupby('UID')[feature].sum().reset_index()\n",
    "                    temp.columns = ['UID',feature+deliver]\n",
    "                    label =label.merge(temp,on='UID',how='left')\n",
    "                    del temp\n",
    "                    temp = trans[['UID',deliver]].merge(trans.groupby([deliver])[feature].max().reset_index(),on=deliver,how='left')[['UID',feature]] \n",
    "                    temp = temp.groupby('UID')[feature].mean().reset_index()\n",
    "                    temp.columns = ['UID',feature+deliver]\n",
    "                    label =label.merge(temp,on='UID',how='left')\n",
    "                    del temp\n",
    "                    temp = trans[['UID',deliver]].merge(trans.groupby([deliver])[feature].min().reset_index(),on=deliver,how='left')[['UID',feature]] \n",
    "                    temp = temp.groupby('UID')[feature].mean().reset_index()\n",
    "                    temp.columns = ['UID',feature+deliver]\n",
    "                    label =label.merge(temp,on='UID',how='left')\n",
    "                    del temp\n",
    "                    temp = trans[['UID',deliver]].merge(trans.groupby([deliver])[feature].sum().reset_index(),on=deliver,how='left')[['UID',feature]] \n",
    "                    temp = temp.groupby('UID')[feature].mean().reset_index()\n",
    "                    temp.columns = ['UID',feature+deliver]\n",
    "                    label =label.merge(temp,on='UID',how='left')\n",
    "                    del temp\n",
    "                    temp = trans[['UID',deliver]].merge(trans.groupby([deliver])[feature].mean().reset_index(),on=deliver,how='left')[['UID',feature]] \n",
    "                    temp = temp.groupby('UID')[feature].mean().reset_index()\n",
    "                    temp.columns = ['UID',feature+deliver]\n",
    "                    label =label.merge(temp,on='UID',how='left')\n",
    "                    del temp\n",
    "                    temp = trans[['UID',deliver]].merge(trans.groupby([deliver])[feature].std().reset_index(),on=deliver,how='left')[['UID',feature]] \n",
    "                    temp = temp.groupby('UID')[feature].mean().reset_index()\n",
    "                    temp.columns = ['UID',feature+deliver]\n",
    "                    label =label.merge(temp,on='UID',how='left')\n",
    "                    del temp\n",
    "    print(\"Done\")\n",
    "    return label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "train = get_feature(op_train,trans_train,y).fillna(-1)\n",
    "test = get_feature(op_test,trans_test,sub).fillna(-1)\n",
    "\n",
    "train = train.drop(['Tag'],axis = 1).fillna(-1)\n",
    "label = y['Tag']\n",
    "\n",
    "test_id = test['UID']\n",
    "test = test.drop(['Tag'],axis = 1).fillna(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 30 rounds.\n",
      "[50]\tvalid_0's binary_logloss: 0.107322\tvalid_1's binary_logloss: 0.126894\n",
      "[100]\tvalid_0's binary_logloss: 0.0716069\tvalid_1's binary_logloss: 0.104521\n",
      "[150]\tvalid_0's binary_logloss: 0.055521\tvalid_1's binary_logloss: 0.0999662\n",
      "[200]\tvalid_0's binary_logloss: 0.045451\tvalid_1's binary_logloss: 0.0985206\n",
      "[250]\tvalid_0's binary_logloss: 0.0385565\tvalid_1's binary_logloss: 0.097803\n",
      "Early stopping, best iteration is:\n",
      "[266]\tvalid_0's binary_logloss: 0.0368486\tvalid_1's binary_logloss: 0.0977156\n",
      "[0.09771560798150823]\n",
      "Training until validation scores don't improve for 30 rounds.\n",
      "[50]\tvalid_0's binary_logloss: 0.10768\tvalid_1's binary_logloss: 0.124557\n",
      "[100]\tvalid_0's binary_logloss: 0.0725487\tvalid_1's binary_logloss: 0.102494\n",
      "[150]\tvalid_0's binary_logloss: 0.0565899\tvalid_1's binary_logloss: 0.0967596\n",
      "[200]\tvalid_0's binary_logloss: 0.046413\tvalid_1's binary_logloss: 0.0942128\n",
      "[250]\tvalid_0's binary_logloss: 0.0393962\tvalid_1's binary_logloss: 0.0929044\n",
      "[300]\tvalid_0's binary_logloss: 0.0343551\tvalid_1's binary_logloss: 0.0924109\n",
      "[350]\tvalid_0's binary_logloss: 0.0306645\tvalid_1's binary_logloss: 0.0922117\n",
      "Early stopping, best iteration is:\n",
      "[327]\tvalid_0's binary_logloss: 0.0322159\tvalid_1's binary_logloss: 0.0921802\n",
      "[0.09771560798150823, 0.09218021834393177]\n",
      "Training until validation scores don't improve for 30 rounds.\n",
      "[50]\tvalid_0's binary_logloss: 0.108134\tvalid_1's binary_logloss: 0.124706\n",
      "[100]\tvalid_0's binary_logloss: 0.072652\tvalid_1's binary_logloss: 0.103172\n",
      "[150]\tvalid_0's binary_logloss: 0.056555\tvalid_1's binary_logloss: 0.0970262\n",
      "[200]\tvalid_0's binary_logloss: 0.0465211\tvalid_1's binary_logloss: 0.094963\n",
      "[250]\tvalid_0's binary_logloss: 0.0395835\tvalid_1's binary_logloss: 0.094238\n",
      "[300]\tvalid_0's binary_logloss: 0.034603\tvalid_1's binary_logloss: 0.0940868\n",
      "[350]\tvalid_0's binary_logloss: 0.0308739\tvalid_1's binary_logloss: 0.09404\n",
      "Early stopping, best iteration is:\n",
      "[341]\tvalid_0's binary_logloss: 0.0314723\tvalid_1's binary_logloss: 0.0939238\n",
      "[0.09771560798150823, 0.09218021834393177, 0.09392382983300407]\n",
      "Training until validation scores don't improve for 30 rounds.\n",
      "[50]\tvalid_0's binary_logloss: 0.105906\tvalid_1's binary_logloss: 0.132548\n",
      "[100]\tvalid_0's binary_logloss: 0.070138\tvalid_1's binary_logloss: 0.11216\n",
      "[150]\tvalid_0's binary_logloss: 0.0541442\tvalid_1's binary_logloss: 0.107429\n",
      "[200]\tvalid_0's binary_logloss: 0.0442281\tvalid_1's binary_logloss: 0.106252\n",
      "Early stopping, best iteration is:\n",
      "[211]\tvalid_0's binary_logloss: 0.042554\tvalid_1's binary_logloss: 0.106172\n",
      "[0.09771560798150823, 0.09218021834393177, 0.09392382983300407, 0.1061716348804787]\n",
      "Training until validation scores don't improve for 30 rounds.\n",
      "[50]\tvalid_0's binary_logloss: 0.108027\tvalid_1's binary_logloss: 0.126988\n",
      "[100]\tvalid_0's binary_logloss: 0.0724258\tvalid_1's binary_logloss: 0.104276\n",
      "[150]\tvalid_0's binary_logloss: 0.0560862\tvalid_1's binary_logloss: 0.0986655\n",
      "[200]\tvalid_0's binary_logloss: 0.0459888\tvalid_1's binary_logloss: 0.0968149\n",
      "[250]\tvalid_0's binary_logloss: 0.0390008\tvalid_1's binary_logloss: 0.0961935\n",
      "[300]\tvalid_0's binary_logloss: 0.0341262\tvalid_1's binary_logloss: 0.0961379\n",
      "Early stopping, best iteration is:\n",
      "[288]\tvalid_0's binary_logloss: 0.0351364\tvalid_1's binary_logloss: 0.0960867\n",
      "[0.09771560798150823, 0.09218021834393177, 0.09392382983300407, 0.1061716348804787, 0.0960867325277003]\n",
      "0.7901050175029172\n"
     ]
    }
   ],
   "source": [
    "lgb_model = lgb.LGBMClassifier(boosting_type='gbdt', num_leaves=64, reg_alpha=3, reg_lambda=5, max_depth=-1,\n",
    "    n_estimators=1000, objective='binary', subsample=0.9, colsample_bytree=0.77, subsample_freq=1, learning_rate=0.05,\n",
    "    random_state=3333, n_jobs=16, min_child_weight=4, min_child_samples=5, min_split_gain=0)\n",
    "skf = StratifiedKFold(n_splits=5, random_state=8888, shuffle=True)\n",
    "best_score = []\n",
    "\n",
    "oof_preds = np.zeros(train.shape[0])\n",
    "sub_preds = np.zeros(test_id.shape[0])\n",
    "\n",
    "for index, (train_index, test_index) in enumerate(skf.split(train, label)):\n",
    "    lgb_model.fit(train.iloc[train_index], label.iloc[train_index], verbose=50,\n",
    "                  eval_set=[(train.iloc[train_index], label.iloc[train_index]),\n",
    "                            (train.iloc[test_index], label.iloc[test_index])], early_stopping_rounds=30)\n",
    "    best_score.append(lgb_model.best_score_['valid_1']['binary_logloss'])\n",
    "    print(best_score)\n",
    "    oof_preds[test_index] = lgb_model.predict_proba(train.iloc[test_index], num_iteration=lgb_model.best_iteration_)[:,1]\n",
    "\n",
    "    test_pred = lgb_model.predict_proba(test, num_iteration=lgb_model.best_iteration_)[:, 1]\n",
    "    sub_preds += test_pred / 5\n",
    "    #print('test mean:', test_pred.mean())\n",
    "    #predict_result['predicted_score'] = predict_result['predicted_score'] + test_pred\n",
    "\n",
    "m = tpr_weight_funtion(y_predict=oof_preds,y_true=label)\n",
    "print(m[1])\n",
    "sub = pd.read_csv('../data/example.csv')\n",
    "sub['Tag'] = sub_preds\n",
    "sub.to_csv('../result/model_3.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
